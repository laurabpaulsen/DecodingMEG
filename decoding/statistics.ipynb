{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm \n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_accuracy(accuracies, diagonal = True):\n",
    "    \"\"\"\n",
    "    Return the maximum accuracy for each session.\n",
    "    \"\"\"\n",
    "    # average over folds\n",
    "    avg = np.mean(accuracies, axis=1)\n",
    "\n",
    "    acc_max = []\n",
    "    for i in range(avg.shape[0]): # looping over sessions\n",
    "        if diagonal:\n",
    "            max_acc = np.max(avg[i].diagonal())\n",
    "        else:\n",
    "            max_acc = np.max(avg[i])\n",
    "        acc_max.append(max_acc)\n",
    "    \n",
    "    return acc_max"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model to investigates the effects of the decoding strategy given the variablity of the ERF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/anaconda3/envs/mne/lib/python3.10/site-packages/scipy/stats/_stats_py.py:1769: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=14\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>accuracy</td>     <th>  R-squared:         </th> <td>   0.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.674</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Dec 2022</td> <th>  Prob (F-statistic):</th>  <td> 0.104</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:46:11</td>     <th>  Log-Likelihood:    </th> <td>  42.623</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    14</td>      <th>  AIC:               </th> <td>  -77.25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    10</td>      <th>  BIC:               </th> <td>  -74.69</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>    0.8482</td> <td>    0.099</td> <td>    8.585</td> <td> 0.000</td> <td>    0.628</td> <td>    1.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>strategy</th>     <td>    0.0085</td> <td>    0.140</td> <td>    0.061</td> <td> 0.953</td> <td>   -0.303</td> <td>    0.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std</th>          <td>   -5.6189</td> <td>    2.947</td> <td>   -1.907</td> <td> 0.086</td> <td>  -12.184</td> <td>    0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>strategy:std</th> <td>   -0.3648</td> <td>    4.167</td> <td>   -0.088</td> <td> 0.932</td> <td>   -9.650</td> <td>    8.920</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.904</td> <th>  Durbin-Watson:     </th> <td>   1.687</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.636</td> <th>  Jarque-Bera (JB):  </th> <td>   0.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.383</td> <th>  Prob(JB):          </th> <td>   0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.881</td> <th>  Cond. No.          </th> <td>1.50e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.5e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               accuracy   R-squared:                       0.445\n",
       "Model:                            OLS   Adj. R-squared:                  0.279\n",
       "Method:                 Least Squares   F-statistic:                     2.674\n",
       "Date:                Wed, 14 Dec 2022   Prob (F-statistic):              0.104\n",
       "Time:                        09:46:11   Log-Likelihood:                 42.623\n",
       "No. Observations:                  14   AIC:                            -77.25\n",
       "Df Residuals:                      10   BIC:                            -74.69\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept        0.8482      0.099      8.585      0.000       0.628       1.068\n",
       "strategy         0.0085      0.140      0.061      0.953      -0.303       0.320\n",
       "std             -5.6189      2.947     -1.907      0.086     -12.184       0.947\n",
       "strategy:std    -0.3648      4.167     -0.088      0.932      -9.650       8.920\n",
       "==============================================================================\n",
       "Omnibus:                        0.904   Durbin-Watson:                   1.687\n",
       "Prob(Omnibus):                  0.636   Jarque-Bera (JB):                0.350\n",
       "Skew:                          -0.383   Prob(JB):                        0.840\n",
       "Kurtosis:                       2.881   Cond. No.                     1.50e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.5e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbo_file = 'accuracies_LDA_lbo'\n",
    "lbo = np.load(f'accuracies/{lbo_file}.npy')\n",
    "\n",
    "propb_file = 'accuracies_LDA_prop'\n",
    "propb = np.load(f'accuracies/{propb_file}.npy')\n",
    "\n",
    "lbo_acc = max_accuracy(lbo, diagonal = False)\n",
    "propb_acc = max_accuracy(propb, diagonal = False)\n",
    "\n",
    "# standard deviation within session\n",
    "std_sessions = np.load('../ERF_analysis/std_sessions.npy')\n",
    "# average over timepoints\n",
    "std_sessions = np.mean(std_sessions, axis=1)\n",
    "# standard deviation within session\n",
    "std_sessions = np.load('../ERF_analysis/std_sessions.npy')\n",
    "# average over timepoints\n",
    "std_sessions = np.mean(std_sessions, axis=1)\n",
    "\n",
    "### preparing design matrix ###\n",
    "strategy = np.array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1])\n",
    "accuracy = np.array(lbo_acc + propb_acc)\n",
    "std = np.concatenate([std_sessions, std_sessions])\n",
    "\n",
    "# create the design matrix\n",
    "design = pd.DataFrame({'strategy': strategy, 'std': std, 'accuracy': accuracy})\n",
    "\n",
    "y, X = dmatrices('accuracy ~ strategy + std + strategy:std', design)\n",
    "#y, X = dmatrices('accuracy ~ strategy:std', design)\n",
    "mod = sm.OLS(y, X)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'cross_decoding_ncv_5'\n",
    "cross = np.load(f'accuracies/{file}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>accuracy</td>     <th>  R-squared:         </th> <td>   0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Dec 2022</td> <th>  Prob (F-statistic):</th>  <td>0.0733</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:31:54</td>     <th>  Log-Likelihood:    </th> <td>  112.63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    49</td>      <th>  AIC:               </th> <td>  -219.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>  -213.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.8248</td> <td>    0.097</td> <td>    8.499</td> <td> 0.000</td> <td>    0.629</td> <td>    1.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_train</th> <td>   -2.3093</td> <td>    2.048</td> <td>   -1.128</td> <td> 0.265</td> <td>   -6.432</td> <td>    1.813</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_test</th>  <td>   -4.2291</td> <td>    2.048</td> <td>   -2.065</td> <td> 0.045</td> <td>   -8.352</td> <td>   -0.107</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17.671</td> <th>  Durbin-Watson:     </th> <td>   1.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  21.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.386</td> <th>  Prob(JB):          </th> <td>2.45e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.649</td> <th>  Cond. No.          </th> <td>    573.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               accuracy   R-squared:                       0.107\n",
       "Model:                            OLS   Adj. R-squared:                  0.069\n",
       "Method:                 Least Squares   F-statistic:                     2.768\n",
       "Date:                Wed, 14 Dec 2022   Prob (F-statistic):             0.0733\n",
       "Time:                        13:31:54   Log-Likelihood:                 112.63\n",
       "No. Observations:                  49   AIC:                            -219.3\n",
       "Df Residuals:                      46   BIC:                            -213.6\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.8248      0.097      8.499      0.000       0.629       1.020\n",
       "std_train     -2.3093      2.048     -1.128      0.265      -6.432       1.813\n",
       "std_test      -4.2291      2.048     -2.065      0.045      -8.352      -0.107\n",
       "==============================================================================\n",
       "Omnibus:                       17.671   Durbin-Watson:                   1.888\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.230\n",
       "Skew:                           1.386   Prob(JB):                     2.45e-05\n",
       "Kurtosis:                       4.649   Cond. No.                         573.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of 7 empty lists\n",
    "accuracies = []\n",
    "\n",
    "for i in range(7):\n",
    "    tmp = cross[i, :, :, :]\n",
    "    for j in range(7):\n",
    "        accuracies.append(np.max(tmp[j, :, :]))\n",
    "\n",
    "\n",
    "# standard deviation within session\n",
    "std_sessions = np.load('../ERF_analysis/std_sessions.npy')\n",
    "# average over timepoints\n",
    "std_sessions = np.mean(std_sessions, axis=1)\n",
    "# standard deviation within session\n",
    "std_sessions = np.load('../ERF_analysis/std_sessions.npy')\n",
    "# average over timepoints\n",
    "std_sessions = np.mean(std_sessions, axis=1)\n",
    "\n",
    "std_test = std_sessions.tolist()*7\n",
    "std_train = [std_sessions[i] for i in range(7) for j in range(7)]\n",
    "\n",
    "\n",
    "# create the design matrix\n",
    "design = pd.DataFrame({'std_test': std_test, 'std_train': std_train, 'accuracy': accuracies})\n",
    "\n",
    "y, X = dmatrices('accuracy ~ std_train + std_test', design)\n",
    "#y, X = dmatrices('accuracy ~ strategy:std', design)\n",
    "mod = sm.OLS(y, X)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine if the decoding accuracy is significantly different from chance level\n",
    "\n",
    "$$P(z) = \\sum_{i=z}^n \\binom{n}{i} \\times \\left(\\frac{1}{c}\\right)^i \\times \\left(\\frac{c-1}{c}\\right)^{n-i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decoding_plots import chance_level\n",
    "chance = chance_level()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "train_0 = cross[0, :, :, :]\n",
    "for t in range(cross.shape[0]):\n",
    "    train = cross[t, :, :, :]\n",
    "    for i in range(7):\n",
    "        dif = train[i, :, :] - chance[i]\n",
    "        # check if any values are positive\n",
    "        if np.any(dif > 0):\n",
    "            print('positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# playground aka mess!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = np.load('./accuracies/accuracies_LDA_props.npy', allow_pickle=True).squeeze() # proportional session\n",
    "\n",
    "for i in range(len(props)):\n",
    "    plt.imshow(props[i], cmap='viridis')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('mne')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c6d417fafcf6fd95c2ae07c3da4aca22733dcf3570acef2375b4229f6bb883b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
